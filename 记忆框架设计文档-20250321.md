以下是最新的"**单用户（Master）+ EVA** 对话与记忆框架设计"文档，移除"二次调用 SensoryBuffer"的环节，并明确在 **retrieve_memory** 阶段就将处理后文本写回 Redis，以便在 **store_memory** 阶段直接复用。此版本可避免重复清洗文本，进一步简化流程。

---

# EVA 单用户对话与记忆框架设计（最终版）

## 一、背景与目标

- **背景**：EVA 作为专属助理，与唯一用户（Master）进行对话，需要多轮记忆能力，并管理规则与长期知识。
- **目标**：在原先简洁的"单用户 + 检索 + 存储"方案上，进一步统一数据格式；即在 SensoryBuffer 预处理后，仅使用处理后的文本进行后续存储、检索与对话上下文拼接，并避免重复清洗。

---

## 二、角色与职责

1. **Master**

   - 系统唯一的人类用户，所有请求都来自 Master。
   - 通过 WebSocket 与后端交互，收到来自 EVA 的回复。

2. **EVA**

   - 虚拟助理形象，由大语言模型（LLM）驱动。
   - 在对话时结合短期记忆、长期记忆与规则信息，为 Master 提供回答。

3. **LLMConsumer（前台逻辑管理）**

   - 接收 Master 的 WebSocket 消息，解析得到 `message_id` 和 `user_message`。
   - 发起对记忆检索与存储的指令给 MemoryConsumer；
   - 调用 LLM（通过 llm_service）生成 EVA 回复，并将结果返回给 Master。

4. **MemoryConsumer（记忆管理中转）**

   - 负责处理 LLMConsumer 的指令：
     - **"检索记忆"（retrieve_memory）**：获取上下文并返回给 LLMConsumer；
     - **"存储记忆"（store_memory）**：将本回合的"用户输入 + LLM 回复"写入短期或长期记忆。
   - 可结合 Redis 等缓存以减少大文本在 Channels 事件中的传输量。

5. **CentralExecutive（记忆中枢）**

   - 整合以下子模块：
     - `SensoryBuffer`：输入文本预处理（文本清洗、情感分析、优先级提取等）；
     - `ConversationBufferMemory`：短期记忆（WorkingTermMemory）；
     - `long_term_memory`：长期记忆（LongTermMemory，Pinecone / JSON 文件，存储前会 similarity_search，分数高于阈值或内容完全相等时不重复存储）；
     - `rule_memory`：规则库（RuleMemory，含冲突检测逻辑）；
     - `hippocampal_encoder`：判断并执行长期记忆巩固。
   - 提供统一接口，如 `combine_context()`，拼接规则记忆、长期记忆、短期记忆，生成 final_context，MemoryConsumer / LLMConsumer 只需直接调用，无需再做二次拼接。
   - `update_working_memory()` 用于写入短期记忆。

6. **Redis（可选，用于缓存）**
   - 在单用户场景下，用作"临时缓存"：以 `message_id` 作为键存储 Master 的输入（以及可能的预处理后文本）；
   - 减少在 Channels 事件中反复传大段文本的开销。

---

## 三、主要数据流

### 1. Master → LLMConsumer

1. **Master** 通过 WebSocket 发出消息，内含文本。
2. **LLMConsumer** 解析得到 `user_message` 与 `message_id`（可自动生成或从前端接收）。
3. **可选**：将原始 `user_message` 暂存到 Redis（键如 `user_msg:{message_id}`），以便后续 MemoryConsumer 拿取。
4. 调用 **MemoryConsumer** 的 **"retrieve_memory"** 事件，只需传 `message_id` 等最少字段。

### 2. MemoryConsumer.retrieve_memory

1. 从 Redis 获取 `user_message`；
2. 调用 **`central_executive.combine_context()`**，其中会：
   - **第一步：SensoryBuffer** 将 `user_message` 清洗/分析，得到 `processed_text`。
   - **写回 Redis**：将 `processed_text` 覆盖保存到 Redis（如 `redis.set("user_msg:{message_id}", processed_text)`），以后就不再保留原文。
   - **后续检索**：只使用 `processed_text` 做规则检索、短期记忆检索、长期记忆检索（长期记忆存储前会 similarity_search，分数高于阈值或内容完全相等时不重复存储，检索时对 query 做归一化，分数为 0 时用内容完全相等判断命中）；
   - **日志详细输出**：每一类记忆内容和最终上下文，便于排查。
3. 整理上下文为 `system_context`（即 final_context）返回给 **LLMConsumer**（通过 Channels 事件）。

### 3. LLMConsumer 调用 LLM

1. **LLMConsumer** 得到 `system_context`（即 final_context），并可从 Redis 里拿到已经清洗后的 `processed_text`；
2. 以 `processed_text` + `system_context` 组装 Prompt，调用大语言模型（LLM）得到 **EVA** 的回答 `response_text`；
3. 将 `response_text` 通过 WebSocket 发送给 **Master**；
4. 同时调用 **MemoryConsumer** 的 **"store_memory"** 事件，携带 `message_id` 与 `response_text`。

### 4. MemoryConsumer.store_memory

1. 从 Redis 读取 **`processed_text`**（此前已覆盖原文）；
2. 调用 **`central_executive.update_working_memory(processed_text, response_text)`** 将对话回合写入短期记忆（ConversationBufferMemory）或进一步存入长期记忆；
3. （可选）删除 Redis 中与 `message_id` 相关的缓存，或设置 TTL 自动过期，释放资源。

> **重要：**  
> 全流程只在 **retrieve_memory** 阶段对原始文本进行一次 SensoryBuffer 处理；然后将 **`processed_text`** 反写到 Redis，所有下游逻辑（LLM Prompt、短期记忆、长期记忆）都使用 **`processed_text`**。  
> 这样能避免二次清洗、保持文本一致性。

---

## 四、单用户特化要点

1. **不存原始文本**

   - SensoryBuffer 一旦完成预处理，Redis 里的 `user_message` 即可被 `processed_text` 覆盖；
   - 后续所有流程都基于 `processed_text`，无须保留原文。

2. **固定会话标识**

   - 单用户模式可将 `session_id` 固定为 "MASTER" 或省略。
   - 短期记忆不必区分多用户，仅需记录多轮对话回合。

3. **简化 Channels 事件**

   - `retrieve_memory` 只需传 `message_id`；
   - `store_memory` 只需传 `message_id` 和 `response_text`；
   - 数据主体都在 Redis 或下游储存中，不在事件间反复传递。

4. **对话记录**
   - 每轮对话结束后，将（`processed_text` + `response_text`）写入 **ConversationBufferMemory**（或你自定义的短期记忆模块）；
   - 若匹配高优先级或包含关键字，可进一步在 `hippocampal_encoder` 中执行长期记忆存储。

---

## 五、后续扩展与注意事项

1. **SensoryBuffer 性能**

   - 确保 SensoryBuffer 清洗/分析不会显著拖慢对话响应。必要时可做异步或分层处理。

2. **合规与审计**

   - 一旦只保留 `processed_text`，若将来需要审计原文，则无法溯源。
   - 如业务可能有这方面需求，可考虑保留"双份数据"或做归档。

3. **记忆数据量**

   - 长期记忆量大时，需考虑检索优化。短期记忆若过长，可定期做摘要或裁剪。

4. **情感与优先级**

   - SensoryBuffer 提供的情感、优先级可直接决定是否进入长期记忆或特殊规则逻辑。

5. **模型升级**
   - 如果变更 LLM 或嵌入模型，需要评估对现有 `processed_text` 的兼容性，以及是否要重新做 embedding。

---

## 六、总结

- 本设计从"检索 + 回答 + 存储"思路出发，在 **retrieve_memory** 阶段唯一一次调用 **SensoryBuffer**；
- 将处理后文本 **`processed_text`** 立即替换 Redis 中的原文，从而**后续各阶段都只使用已清洗文本**；
- combine_context 统一拼接规则记忆、长期记忆、短期记忆，生成 final_context，LLMConsumer 直接用 final_context 作为 prompt，无需再做二次拼接；
- 长期记忆存储前会 similarity_search，分数高于阈值或内容完全相等时不重复存储，检索时对 query 做归一化，分数为 0 时用内容完全相等判断命中；
- 日志详细输出每一类记忆内容和最终上下文，便于排查；
- 单用户情境下，事件结构精简、Redis 使用轻量，利于维护并可平滑扩展。

【补充：记忆系统智能优化与自我进化能力】
- 统计字段（如时间戳、引用次数、优先级等）已统一格式，便于统计、排序、清理。
- 清理策略已智能化，综合优先级、标签、引用次数、时间等多维度，自动淘汰低价值内容。
- 内容归纳与冲突融合已本地实现，自动合并相似规则，减少冗余。
- 检索结果多维度加权排序，优先推荐最相关、最常用、最重要、最新内容。
- 日志与异常处理细化，便于追溯和维护。
- 支持主动推理与内容自我优化，系统能定期分析并优化规则内容，实现"越用越懂你"。
- 支持外部知识库联动与自动化执行，规则可自动同步外部知识并触发实际动作。
- 以上能力已全部落地，记忆系统具备自我进化能力。

若将来发现确有需保留原文本以做审计或训练，可以按需恢复或额外存储 `raw_text`。在当前场景下，本方案能最大化减少数据冗余、简化实现和增强一致性。

EVA_backend/memory_service_app/utils/long_term_memory/long_term_memory.py 代码框架
│
├── **1. 连接管理 (`MemoryConnector`)**
│ ├── 初始化 Pinecone 连接 (`initialize()`)
│ ├── 确保连接已初始化 (`ensure_initialized()`)
│ ├── 增加自动重试机制
│ ├── 缓存索引状态
│
├── **2. 记忆检索 (`MemoryRetrieval`)**
│ ├── **语义检索**（**embedding 为主**）(`retrieve_memory()`)
│ ├── **关联点补充检索**（**调用 `association_manager.match_associations()`**）
│ ├── 根据 ID 检索 (`retrieve_memory_by_id()`)
│ ├── 支持 session 过滤
│ ├── 增加缓存
│
├── **3. 记忆存储 (`MemoryStorage`)**
│ ├── **存储新记忆**（**语义存储为主，关联点为辅**）(`store_memory()`)
│ ├── **更新记忆**（**合并旧数据**）(`update_memory()`)
│ ├── **删除记忆**（**自动更新关联点**）(`delete_memory()`)
│ ├── **存储时自动建立关联**（**调用 `association_manager.generate_associations()`**）
│
├── **4. 记忆分类 (`MemoryCategorization`)**
│ ├── 通过 LLM 预测记忆类别 (`categorize_memory()`)
│ ├── 失败时使用 NLP 规则进行分类
│ ├── 失败时基于历史数据推测分类
│
└── **5. 记忆冲突 (`MemoryConflictResolver`)**
├── **调用 `memory_conflict_resolver.py` 进行冲突解析** (`resolve_conflict()`)
├── **不在 `long_term_memory.py` 里单独实现冲突处理**

rule_memory.py 代码框架
│
├── **1. 连接管理 (`RuleConnector`)**
│ ├── 负责 Pinecone 连接、初始化 (`initialize()`, `ensure_initialized()`)
│
├── **2. 规则存储 (`RuleStorage`)**
│ ├── 处理规则存储 (`store_rule()`)
│ ├── 处理规则更新 (`update_rule()`)
│ ├── 处理规则删除 (`delete_rule()`)
│
├── **3. 规则检索 (`RuleRetrieval`)**
│ ├── 处理规则查询 (`retrieve_rule()`, `retrieve_rule_by_id()`)
│
├── **4. 规则分类 (`RuleCategorization`)**
│ ├── 通过 NLP 规则和 LLM 进行分类 (`categorize_rule()`)
│
└── **5. 规则冲突 (`RuleConflictResolver`)**
├── 处理规则冲突 (`resolve_conflict()`)
